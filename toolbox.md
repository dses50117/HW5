import streamlit as st
import pandas as pd
import numpy as np
import plotly.graph_objects as go
import plotly.express as px
import re
import time

# --- é é¢è¨­å®š ---
st.set_page_config(
    page_title="AI vs Human æ–‡æœ¬åµæ¸¬å™¨ Pro",
    page_icon="ğŸ•µï¸â€â™‚ï¸",
    layout="wide",
    initial_sidebar_state="expanded"
)

# --- è‡ªå®šç¾© CSS ---
st.markdown("""
<style>
    .main { background-color: #0e1117; }
    .stTextArea textarea { font-size: 16px; line-height: 1.6; border-radius: 10px; }
    .highlight-ai { background-color: #ff4b4b4d; border-radius: 4px; padding: 2px 4px; border-bottom: 2px solid #ff4b4b; }
    .metric-card { background-color: #262730; padding: 20px; border-radius: 10px; text-align: center; }
    h1, h2, h3 { font-family: 'Helvetica Neue', sans-serif; }
</style>
""", unsafe_allow_html=True)

# --- æ¨¡å‹è¼‰å…¥ç®¡ç† (Hugging Face) ---
@st.cache_resource
def load_hf_model():
    """
    å˜—è©¦è¼‰å…¥ Hugging Face æ¨¡å‹ã€‚
    å¦‚æœä½¿ç”¨è€…æ²’æœ‰å®‰è£ transformers/torchï¼Œæˆ–æ˜¯ä¸‹è¼‰å¤±æ•—ï¼Œå›å‚³ Noneã€‚
    """
    try:
        from transformers import pipeline
        # ä½¿ç”¨ä¸€å€‹è¼•é‡ä¸”æ•ˆæœä¸éŒ¯çš„å…¬é–‹æ¨¡å‹
        # Hello-SimpleAI/chatgpt-detector-roberta æ˜¯åŸºæ–¼ RoBERTa å¾®èª¿çš„æ¨¡å‹
        detector = pipeline("text-classification", model="Hello-SimpleAI/chatgpt-detector-roberta", top_k=None)
        return detector
    except ImportError:
        return "MISSING_LIB"
    except Exception as e:
        return f"ERROR: {str(e)}"

# --- åˆ†æé‚è¼¯ ---

def analyze_text(text, use_hf_model=True):
    if not text:
        return None

    # åŸºç¤çµ±è¨ˆç‰¹å¾µ (ç„¡è«–æ˜¯å¦ç”¨ AI æ¨¡å‹éƒ½éœ€è¦)
    sentences = re.split(r'[.!?ã€‚ï¼ï¼Ÿ]+', text)
    sentences = [s.strip() for s in sentences if len(s.strip()) > 1]
    words = re.findall(r'\w+', text)
    sent_lengths = [len(s) for s in sentences]
    
    if len(sentences) == 0 or len(words) == 0:
        return None

    std_sent_len = np.std(sent_lengths) if sent_lengths else 0
    
    result = {
        "sentences": sentences,
        "sent_lengths": sent_lengths,
        "std_dev": std_sent_len,
        "word_count": len(words),
        "sentence_count": len(sentences),
        "mode": "Simulation" # é è¨­æ¨¡å¼
    }

    # --- åˆ†æ”¯ 1: ä½¿ç”¨ Hugging Face æ¨¡å‹ (çœŸå¯¦ AI åµæ¸¬) ---
    if use_hf_model:
        hf_detector = load_hf_model()
        
        # æª¢æŸ¥æ˜¯å¦æˆåŠŸè¼‰å…¥
        if hf_detector == "MISSING_LIB":
            st.toast("âš ï¸ æœªå®‰è£ transformersï¼Œåˆ‡æ›å›æ¨¡æ“¬æ¨¡å¼", icon="ğŸ”§")
        elif isinstance(hf_detector, str) and hf_detector.startswith("ERROR"):
            st.toast(f"âš ï¸ æ¨¡å‹è¼‰å…¥å¤±æ•—ï¼Œåˆ‡æ›å›æ¨¡æ“¬æ¨¡å¼", icon="âš ï¸")
        elif hf_detector:
            # æˆåŠŸè¼‰å…¥çœŸæ¨¡å‹
            result["mode"] = "Hugging Face (RoBERTa)"
            
            # å› ç‚ºæ¨¡å‹æœ‰è¼¸å…¥é•·åº¦é™åˆ¶ (é€šå¸¸ 512 tokens)ï¼Œæˆ‘å€‘å–å‰ 512 å­—å…ƒåšå¿«é€Ÿé æ¸¬
            # ç”Ÿç”¢ç’°å¢ƒæ‡‰è©²è¦åšåˆ‡å¡Š (chunking) å†å¹³å‡ï¼Œé€™è£¡åšç°¡åŒ–è™•ç†
            truncated_text = text[:1000] 
            predictions = hf_detector(truncated_text)[0]
            
            # è§£æé æ¸¬çµæœ
            # æ¨¡å‹è¼¸å‡ºç¯„ä¾‹: [{'label': 'ChatGPT', 'score': 0.98}, {'label': 'Human', 'score': 0.02}]
            ai_score = 0.0
            for pred in predictions:
                if pred['label'] == 'ChatGPT' or pred['label'] == 'Fake':
                    ai_score = pred['score'] * 100
                elif pred['label'] == 'Human' or pred['label'] == 'Real':
                    # å¦‚æœæ˜¯ Human åˆ†æ•¸ï¼ŒAI åˆ†æ•¸å°±æ˜¯ 100 - Human
                    pass 
            
            # å¦‚æœæ¨¡å‹ä¸»è¦æ¨™ç±¤å°±æ˜¯ Humanï¼Œæˆ‘å€‘éœ€è¦è½‰æ›åˆ†æ•¸é‚è¼¯
            top_label = predictions[0]['label']
            top_score = predictions[0]['score']
            
            if top_label in ['Human', 'Real']:
                ai_score = (1 - top_score) * 100
            elif top_label in ['ChatGPT', 'Fake']:
                ai_score = top_score * 100
                
            result["ai_probability"] = ai_score
            return result

    # --- åˆ†æ”¯ 2: çµ±è¨ˆæ¨¡æ“¬æ¨¡å¼ (ç•¶æ²’æœ‰å®‰è£ TF æ™‚çš„å‚™æ¡ˆ) ---
    # è¨ˆç®—è©å½™è±å¯Œåº¦
    unique_words = len(set(words))
    ttr = unique_words / len(words) if len(words) > 0 else 0
    
    ai_score = 0
    regularity_score = max(0, 100 - (std_sent_len * 2)) 
    ai_score += regularity_score * 0.4
    
    common_connectors = ['the', 'and', 'is', 'of', 'to', 'çš„', 'æ˜¯', 'åœ¨', 'æœ‰', 'å’Œ']
    connector_count = sum(1 for w in words if w.lower() in common_connectors)
    connector_density = connector_count / len(words)
    
    if connector_density > 0.35: 
        ai_score += 20
        
    final_score = min(98, max(2, ai_score + 30))
    import random
    noise = random.uniform(-5, 5)
    final_score = min(100, max(0, final_score + noise))
    
    result["ai_probability"] = final_score
    return result

# --- UI å…ƒä»¶ ---

def draw_gauge_chart(score):
    color = "green" if score < 40 else "orange" if score < 70 else "red"
    fig = go.Figure(go.Indicator(
        mode = "gauge+number",
        value = score,
        domain = {'x': [0, 1], 'y': [0, 1]},
        title = {'text': "AI ç”Ÿæˆå¯èƒ½æ€§ (%)", 'font': {'size': 24}},
        gauge = {
            'axis': {'range': [None, 100], 'tickwidth': 1, 'tickcolor': "white"},
            'bar': {'color': color},
            'steps': [
                {'range': [0, 40], 'color': 'rgba(0, 255, 0, 0.3)'},
                {'range': [40, 70], 'color': 'rgba(255, 165, 0, 0.3)'},
                {'range': [70, 100], 'color': 'rgba(255, 0, 0, 0.3)'}],
            'threshold': {'line': {'color': "white", 'width': 4}, 'thickness': 0.75, 'value': score}
        }))
    fig.update_layout(height=300, margin=dict(l=20, r=20, t=50, b=20), paper_bgcolor="rgba(0,0,0,0)")
    return fig

def draw_complexity_chart(sent_lengths):
    df = pd.DataFrame({'å¥å­åºè™Ÿ': range(1, len(sent_lengths) + 1), 'é•·åº¦ (å­—æ•¸)': sent_lengths})
    fig = px.bar(df, x='å¥å­åºè™Ÿ', y='é•·åº¦ (å­—æ•¸)', title="å¥å­çµæ§‹çˆ†ç™¼åº¦ (Burstiness)")
    fig.update_layout(paper_bgcolor="rgba(0,0,0,0)", plot_bgcolor="rgba(0,0,0,0)", font=dict(color="white"), showlegend=False)
    fig.update_traces(marker_color='#00d4ff')
    return fig

# --- ä¸»ç¨‹å¼ ---

def main():
    # é å…ˆæª¢æŸ¥ç’°å¢ƒ
    hf_status = load_hf_model()
    model_status_text = "ğŸ”´ çµ±è¨ˆæ¨¡æ“¬æ¨¡å¼"
    model_status_color = "off"
    
    if hf_status and hf_status != "MISSING_LIB" and not isinstance(hf_status, str):
        model_status_text = "ğŸŸ¢ Hugging Face (RoBERTa)"
        model_status_color = "on"
    
    with st.sidebar:
        st.header("âš™ï¸ ç³»çµ±æ ¸å¿ƒè¨­å®š")
        
        # é¡¯ç¤ºç•¶å‰ä½¿ç”¨çš„å¼•æ“
        st.markdown(f"**ç›®å‰å¼•æ“:**")
        if model_status_color == "on":
            st.success(model_status_text)
        else:
            st.warning(model_status_text)
            if hf_status == "MISSING_LIB":
                st.caption("ğŸ’¡ æç¤º: å®‰è£ `torch transformers` å¯å•Ÿç”¨ AI æ¨¡å¼")

        use_hf = st.toggle("å•Ÿç”¨ Hugging Face æ¨¡å‹", value=(model_status_color == "on"), disabled=(model_status_color == "off"))
        
        st.markdown("---")
        st.markdown("### é—œæ–¼åŸç†")
        st.info("Hugging Face æ¨¡å¼ä½¿ç”¨ `Hello-SimpleAI/chatgpt-detector-roberta` æ¨¡å‹é€²è¡Œæ·±åº¦èªç¾©åˆ†æã€‚")

    st.title("ğŸ•µï¸â€â™‚ï¸ AI Content Detector Pro")
    st.markdown("è²¼ä¸Šæ–‡ç« ï¼Œç³»çµ±å°‡åˆ†æå…¶æ˜¯å¦ç”± ChatGPTã€Claude æˆ– Gemini ç­‰ AI ç”Ÿæˆã€‚")

    text_input = st.text_area("åœ¨æ­¤è¼¸å…¥æ–‡ç« :", height=200, placeholder="è«‹è²¼ä¸Šå…§å®¹...")

    col1, col2 = st.columns([1, 1])
    analyze_btn = col1.button("ğŸ” é–‹å§‹åˆ†æ", type="primary", use_container_width=True)
    
    if analyze_btn and text_input:
        if len(text_input) < 10:
            st.warning("âš ï¸ æ–‡æœ¬éçŸ­")
        else:
            with st.spinner(f"æ­£åœ¨ä½¿ç”¨ {model_status_text} åˆ†æä¸­..."):
                # åˆ†æ
                result = analyze_text(text_input, use_hf_model=use_hf)
                
                if result:
                    st.divider()
                    
                    # çµæœé¡¯ç¤ºå€
                    st.caption(f"åˆ†ææ¨¡å¼: {result.get('mode', 'Unknown')}")
                    
                    g_col1, g_col2 = st.columns([1, 2])
                    with g_col1:
                        st.plotly_chart(draw_gauge_chart(result['ai_probability']), use_container_width=True)
                    
                    with g_col2:
                        st.subheader("ğŸ“Š åˆ†ææŒ‡æ¨™")
                        m1, m2, m3 = st.columns(3)
                        m1.metric("ç¸½å­—æ•¸", result['word_count'])
                        m2.metric("å¥å­æ•¸é‡", result['sentence_count'])
                        m3.metric("çµæ§‹è®Šç•°æ•¸", f"{result['std_dev']:.2f}")
                        
                        score = result['ai_probability']
                        if score > 80:
                            st.error(f"**é«˜åº¦ç–‘ä¼¼ AI ç”Ÿæˆ** ({score:.1f}%)")
                        elif score > 50:
                            st.warning(f"**ç–‘ä¼¼æ··åˆå…§å®¹** ({score:.1f}%)")
                        else:
                            st.success(f"**æ¥µå¯èƒ½æ˜¯äººé¡æ’°å¯«** ({score:.1f}%)")

                    st.plotly_chart(draw_complexity_chart(result['sent_lengths']), use_container_width=True)
                    
                    # åªæœ‰åœ¨åˆ†æ•¸é«˜æ™‚æ‰é¡¯ç¤ºé«˜äº®å»ºè­°
                    if score > 50:
                        st.subheader("ğŸ” å¥å­æ¨™è¨˜ (é«˜é¢¨éšªå€æ®µ)")
                        highlighted_text = ""
                        for sentence in result['sentences']:
                            # å¦‚æœæ˜¯çœŸ AI æ¨¡å‹ï¼Œæˆ‘å€‘å¯ä»¥å‡è¨­æ•´æ®µéƒ½è¢«åˆ¤å®šï¼Œé€™è£¡åƒ…åšè¦–è¦ºåŒ–æ¨¡æ“¬
                            # è‹¥è¦ç²¾ç¢ºåˆ°å¥å­ï¼Œéœ€è¦å°‡æ¯å€‹å¥å­å–®ç¨ä¸Ÿé€²æ¨¡å‹ (æœƒå¾ˆæ…¢)
                            # é€™è£¡æ¡ç”¨æ··åˆé‚è¼¯ï¼šå¦‚æœæ•´ç¯‡æ˜¯ AIï¼Œå‰‡æ¨™è¨˜çµæ§‹æœ€å®Œç¾çš„å¥å­
                            is_suspicious = abs(len(sentence) - np.mean(result['sent_lengths'])) < (result['std_dev'] * 0.8)
                            
                            if is_suspicious:
                                highlighted_text += f'<span class="highlight-ai">{sentence}</span> '
                            else:
                                highlighted_text += f'<span>{sentence}</span> '
                        
                        st.markdown(f'<div style="background-color: #1e1e1e; padding: 20px; border-radius: 10px; line-height: 2.0;">{highlighted_text}</div>', unsafe_allow_html=True)

if __name__ == "__main__":
    main()