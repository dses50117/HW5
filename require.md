0. å»ºä¸€å€‹å°ˆæ¡ˆè³‡æ–™å¤¾

å‡è¨­å°ˆæ¡ˆå«ï¼š

mkdir ai-content-detector
cd ai-content-detector
mkdir data model

1. å®‰è£å¿…è¦å¥—ä»¶

åœ¨å°ˆæ¡ˆè³‡æ–™å¤¾è£¡åŸ·è¡Œï¼š

pip install transformers datasets torch scikit-learn evaluate streamlit


ä¹‹å¾Œ requirements.txt æœƒå¯«çµ¦ä½ ã€‚

2. å¾ Hugging Face ä¸‹è¼‰ HC3 è³‡æ–™é›†ä¸¦æ•´ç†æˆ CSV

æˆ‘å€‘ç”¨ Hello-SimpleAI/HC3 çš„è‹±æ–‡ç‰ˆæœ¬ï¼Œé€™å€‹è³‡æ–™é›†è£¡æœ‰ï¼š

question

human_answersï¼ˆäººé¡å›ç­”åˆ—è¡¨ï¼‰

chatgpt_answersï¼ˆChatGPT å›ç­”åˆ—è¡¨ï¼‰
Hugging Face

æ–°å»º prepare_data.pyï¼š

# prepare_data.py
from datasets import load_dataset
import pandas as pd
import os

os.makedirs("data", exist_ok=True)

# 1. ä¸‹è¼‰ HC3 è‹±æ–‡è³‡æ–™é›†ï¼ˆsubset: allï¼‰
ds = load_dataset("Hello-SimpleAI/HC3", "all")  # train split by default

train_split = ds["train"]

rows = []

for item in train_split:
    question = item["question"]
    human_answers = item["human_answers"]
    chatgpt_answers = item["chatgpt_answers"]

    # å–æ¯å€‹å•é¡Œçš„ç¬¬ä¸€å€‹äººé¡å›ç­” & ç¬¬ä¸€å€‹ ChatGPT å›ç­”
    if human_answers:
        rows.append({
            "text": human_answers[0],
            "label": "human"
        })
    if chatgpt_answers:
        rows.append({
            "text": chatgpt_answers[0],
            "label": "ai"
        })

df = pd.DataFrame(rows)
print(df["label"].value_counts())
print("Total samples:", len(df))

# å­˜æˆ CSV
out_path = "data/hc3_ai_human.csv"
df.to_csv(out_path, index=False)
print("âœ… Saved:", out_path)


åŸ·è¡Œï¼š

python prepare_data.py


å®Œæˆå¾Œä½ æœƒå¾—åˆ°ï¼šdata/hc3_ai_human.csvï¼Œå…§å«å…©æ¬„ï¼štext, labelã€‚

3. åœ¨æœ¬åœ°è¨“ç·´ Hugging Face æ¨¡å‹ï¼ˆDistilBERTï¼‰

æ–°å»º train.pyï¼š

# train.py
import os
import numpy as np
import pandas as pd
from datasets import Dataset
from sklearn.model_selection import train_test_split

import evaluate
from transformers import (
    AutoTokenizer,
    AutoModelForSequenceClassification,
    TrainingArguments,
    Trainer,
)

MODEL_NAME = "distilbert-base-uncased"
DATA_PATH = "data/hc3_ai_human.csv"
OUTPUT_DIR = "model"

# 1. è®€ CSV
df = pd.read_csv(DATA_PATH)

label2id = {"human": 0, "ai": 1}
id2label = {v: k for k, v in label2id.items()}
df["label_id"] = df["label"].map(label2id)

# 2. Train / Test Split
train_df, test_df = train_test_split(
    df, test_size=0.2, random_state=42, stratify=df["label_id"]
)

train_ds = Dataset.from_pandas(train_df[["text", "label_id"]])
test_ds = Dataset.from_pandas(test_df[["text", "label_id"]])

# 3. Tokenizer
tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)

def preprocess(examples):
    return tokenizer(
        examples["text"],
        truncation=True,
        padding="max_length",
        max_length=256,
    )

train_ds = train_ds.map(preprocess, batched=True)
test_ds = test_ds.map(preprocess, batched=True)

# HF Trainer æ ¼å¼
train_ds = train_ds.remove_columns(["text"])
test_ds = test_ds.remove_columns(["text"])

train_ds = train_ds.rename_column("label_id", "labels")
test_ds = test_ds.rename_column("label_id", "labels")

train_ds.set_format("torch")
test_ds.set_format("torch")

# 4. å»ºç«‹æ¨¡å‹
model = AutoModelForSequenceClassification.from_pretrained(
    MODEL_NAME,
    num_labels=2,
    id2label=id2label,
    label2id=label2id,
)

# 5. è©•ä¼°æŒ‡æ¨™
metric_acc = evaluate.load("accuracy")
metric_f1 = evaluate.load("f1")

def compute_metrics(eval_pred):
    logits, labels = eval_pred
    preds = np.argmax(logits, axis=-1)
    result = {}
    result.update(metric_acc.compute(predictions=preds, references=labels))
    result.update(metric_f1.compute(predictions=preds, references=labels))
    return result

# 6. TrainingArguments
args = TrainingArguments(
    output_dir="model_checkpoints",
    evaluation_strategy="epoch",
    save_strategy="epoch",
    learning_rate=2e-5,
    num_train_epochs=2,  # å¯ä»¥å…ˆè·‘ 2 epoch è©¦è©¦
    per_device_train_batch_size=8,
    per_device_eval_batch_size=16,
    weight_decay=0.01,
    load_best_model_at_end=True,
    metric_for_best_model="accuracy",
)

trainer = Trainer(
    model=model,
    args=args,
    train_dataset=train_ds,
    eval_dataset=test_ds,
    tokenizer=tokenizer,
    compute_metrics=compute_metrics,
)

# 7. è¨“ç·´
trainer.train()

# 8. å„²å­˜æ¨¡å‹åˆ° ./modelï¼ˆä¹‹å¾Œ app è¦è®€é€™å€‹ï¼‰
os.makedirs(OUTPUT_DIR, exist_ok=True)
trainer.save_model(OUTPUT_DIR)
tokenizer.save_pretrained(OUTPUT_DIR)

print("âœ… Model saved to:", OUTPUT_DIR)


åŸ·è¡Œï¼š

python train.py


æˆåŠŸå¾Œï¼Œmodel/ è³‡æ–™å¤¾æœƒæœ‰ï¼š

config.json

pytorch_model.bin

tokenizer.json

tokenizer_config.json

special_tokens_map.json

...

é€™å°±æ˜¯ä½ ä¹‹å¾Œåœ¨ app è£¡è¼‰å…¥çš„ã€Œæœ¬åœ°è¨“ç·´å¥½çš„ AI Detectorã€ã€‚

4. å»º Streamlit Appï¼Œä½¿ç”¨ä½ è‡ªå·±è¨“ç·´çš„æœ¬åœ°æ¨¡å‹

æ–°å»º app.pyï¼š

# app.py
import re
import numpy as np
import torch
import streamlit as st
from transformers import AutoTokenizer, AutoModelForSequenceClassification

MODEL_DIR = "model"  # å°±æ˜¯ train.py å­˜çš„ç›®éŒ„

@st.cache_resource
def load_model():
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    tokenizer = AutoTokenizer.from_pretrained(MODEL_DIR)
    model = AutoModelForSequenceClassification.from_pretrained(MODEL_DIR)
    model.to(device)
    model.eval()
    return tokenizer, model, device

def clean_text(text: str) -> str:
    text = text.replace("\u200b", " ")
    text = text.replace("\n", " ")
    text = re.sub(r"\s+", " ", text)
    return text.strip()

def predict(text: str):
    tokenizer, model, device = load_model()
    text = clean_text(text)

    inputs = tokenizer(
        text,
        truncation=True,
        padding="max_length",
        max_length=256,
        return_tensors="pt",
    )
    inputs = {k: v.to(device) for k, v in inputs.items()}

    with torch.no_grad():
        outputs = model(**inputs)
        logits = outputs.logits.cpu().numpy()[0]
        probs = np.exp(logits) / np.exp(logits).sum()

    # label2id = {"human": 0, "ai": 1}
    human_prob = float(probs[0])
    ai_prob = float(probs[1])
    return human_prob, ai_prob

# ================== Streamlit UI =========================
st.set_page_config(page_title="AI Content Detector", page_icon="ğŸ¤–", layout="wide")

st.title("ğŸ¤– AI Content Detector")
st.write("Detect whether your text is more likely human-written or AI-generated.")
st.caption("Model: DistilBERT fine-tuned on HC3 (Human vs ChatGPT).")

text = st.text_area("Paste your text here", height=220)

col1, col2 = st.columns([1, 1])
with col1:
    analyze_btn = st.button("Analyze", type="primary")
with col2:
    clear_btn = st.button("Clear")

if clear_btn:
    st.experimental_rerun()

if analyze_btn:
    if not text.strip():
        st.warning("Please enter some text to analyze.")
    else:
        with st.spinner("Running local detector model..."):
            human_prob, ai_prob = predict(text)

        human_pct = human_prob * 100
        ai_pct = ai_prob * 100

        st.subheader("Result")
        st.metric("AI Probability", f"{ai_pct:.2f}%")
        st.progress(ai_prob)

        if ai_prob >= 0.7:
            st.error("This text is likely AI-generated.")
        elif ai_prob >= 0.4:
            st.warning("Mixed characteristics of AI and human writing.")
        else:
            st.success("This text is more likely human-written.")

        with st.expander("Details"):
            st.write(f"Human: {human_pct:.2f}%")
            st.write(f"AI: {ai_pct:.2f}%")


æœ¬åœ°æ¸¬è©¦ï¼š

streamlit run app.py


ç¢ºèªåœ¨ç€è¦½å™¨å¯ä»¥æ­£å¸¸è¼¸å…¥æ–‡å­—ã€é¡¯ç¤ºæ©Ÿç‡ã€‚

5. å»ºç«‹ requirements.txt

åœ¨å°ˆæ¡ˆæ ¹ç›®éŒ„æ–°å¢ requirements.txtï¼š

streamlit>=1.30.0
transformers>=4.37.0
datasets>=2.16.0
torch>=2.1.0
scikit-learn>=1.3.0
evaluate>=0.4.0
pandas>=2.0.0

6. æ¨åˆ° GitHub
git init
git add .
git commit -m "AI content detector with local HF model"
git branch -M main
git remote add origin https://github.com/ä½ çš„å¸³è™Ÿ/ai-content-detector.git
git push -u origin main

7. éƒ¨ç½²åˆ° Streamlit Cloud

åˆ° Streamlit Community Cloud
 ç™»å…¥

é»ã€ŒNew appã€

é¸ä½ çš„ GitHub repoï¼šä½ çš„å¸³è™Ÿ/ai-content-detector

Branchï¼šmain

Main file pathï¼šapp.py

é»ã€ŒDeployã€

Streamlit æœƒè‡ªå‹•ï¼š

å®‰è£ requirements.txt

ä½¿ç”¨ repo è£¡çš„ model/ ç›®éŒ„

è·‘ app.py