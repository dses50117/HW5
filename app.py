import streamlit as st
import time
import re
import torch
import plotly.graph_objects as go
from transformers import pipeline
import random

# ==========================================
# 1. é é¢å…¨åŸŸè¨­å®š (å¿…é ˆæ”¾åœ¨ç¨‹å¼ç¢¼æœ€ä¸Šæ–¹)
# ==========================================
st.set_page_config(
    page_title="AI æ–‡æœ¬é‘‘è­˜ç³»çµ±",
    page_icon="ğŸ›¡ï¸",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ==========================================
# 2. CSS æ¨£å¼å„ªåŒ– (æå‡å°ˆæ¥­æ„Ÿ)
# ==========================================
st.markdown(r'''
<style>
    /* èª¿æ•´ä¸»å®¹å™¨é ‚éƒ¨é–“è· */
    .block-container {
        padding-top: 2rem;
        padding-bottom: 3rem;
    }
    /* å„ªåŒ–æ–‡å­—è¼¸å…¥æ¡†å­—é«” */
    .stTextArea textarea {
        font-size: 16px;
        line-height: 1.6;
        font-family: 'Inter', sans-serif;
        border-radius: 10px;
    }
    /* è®“æŒ‰éˆ•æ›´é¡¯çœ¼ */
    .stButton button {
        border-radius: 8px;
        font-weight: 600;
        height: 3em;
    }
    /* çµæœå€å¡Šçš„æ¨£å¼ */
    .result-card {
        padding: 20px;
        border-radius: 10px;
        background-color: #262730;
        margin-top: 20px;
        box-shadow: 0 4px 6px rgba(0,0,0,0.1);
    }
</style>
''', unsafe_allow_html=True)

# ==========================================
# 3. æ ¸å¿ƒåŠŸèƒ½å‡½æ•¸
# ==========================================

@st.cache_resource
def load_detectors():
    """
    è¼‰å…¥å¤šå€‹ Hugging Face æ¨¡å‹ã€‚
    ä½¿ç”¨ @st.cache_resource ç¢ºä¿æ¨¡å‹åªæœƒè¼‰å…¥ä¸€æ¬¡ã€‚
    """
    # æª¢æŸ¥æ˜¯å¦æœ‰ GPU
    device = 0 if torch.cuda.is_available() else -1
    
    # å®šç¾©æ¨¡å‹åˆ—è¡¨ï¼š(é¡¯ç¤ºåç¨±, HuggingFace ID)
    model_info = [
        ("ModernBERT Detector", "AICodexLab/answerdotai-ModernBERT-base-ai-detector"),
        ("RoBERTa Detector", "Hello-SimpleAI/chatgpt-detector-roberta") 
        # å‚™è¨»: Fakespot æ¨¡å‹æœ‰æ™‚å› æˆæ¬Šå•é¡Œç„¡æ³•å…¬é–‹å­˜å–ï¼Œæ”¹ç”¨ Hello-SimpleAI é€™æ¬¾ç©©å®šçš„é–‹æºæ¨¡å‹
    ]
    
    loaded_pipelines = []
    
    for display_name, model_id in model_info:
        try:
            # å˜—è©¦è¼‰å…¥æ¨¡å‹
            pipe = pipeline("text-classification", model=model_id, device=device)
            loaded_pipelines.append({"name": display_name, "pipe": pipe, "id": model_id})
        except Exception as e:
            # å¦‚æœå–®ä¸€æ¨¡å‹å¤±æ•—ï¼Œè¨˜éŒ„éŒ¯èª¤ä½†ä¸ä¸­æ–·ç¨‹å¼
            print(f"âš ï¸ æ¨¡å‹ '{display_name}' è¼‰å…¥å¤±æ•—: {e}")
            # å¯ä»¥é¸æ“‡åœ¨é€™è£¡é¡¯ç¤ºä¸€å€‹ toast
            # st.toast(f"æ¨¡å‹ {display_name} è¼‰å…¥å¤±æ•—ï¼Œå°‡ä½¿ç”¨å…¶ä»–æ¨¡å‹ã€‚", icon="âš ï¸")
    
    return loaded_pipelines

def clean_text(text: str) -> str:
    """æ¸…ç†è¼¸å…¥æ–‡æœ¬ï¼Œç§»é™¤ä¸å¯è¦‹å­—å…ƒ"""
    text = text.replace("\u200b", " ")
    text = text.replace("\n", " ")
    text = re.sub(r"\s+", " ", text)
    return text.strip()

def create_gauge_chart(score, title="ç¶œåˆè©•åˆ†"):
    """
    ç¹ªè£½å°ˆæ¥­çš„å„€è¡¨æ¿åœ–è¡¨
    Score ä»£è¡¨ 'äººé¡æ’°å¯«æ©Ÿç‡' (0-100)
    """
    # é¡è‰²é‚è¼¯ï¼šäººé¡æ©Ÿç‡é«˜(>50)ç‚ºç¶ è‰²ï¼Œä½ç‚ºç´…è‰²
    bar_color = "#10B981" if score > 50 else "#EF4444"
    
    fig = go.Figure(go.Indicator(
        mode = "gauge+number",
        value = score,
        domain = {'x': [0, 1], 'y': [0, 1]},
        title = {'text': title, 'font': {'size': 20, 'color': "gray"}},
        number = {'suffix': "%", 'font': {'size': 40}},
        gauge = {
            'axis': {'range': [None, 100], 'tickwidth': 1, 'tickcolor': "darkblue"},
            'bar': {'color': bar_color},
            'bgcolor': "white",
            'borderwidth': 2,
            'bordercolor': "#E5E7EB",
            'steps': [
                {'range': [0, 50], 'color': 'rgba(239, 68, 68, 0.1)'},  # æ·¡ç´…
                {'range': [50, 100], 'color': 'rgba(16, 185, 129, 0.1)'} # æ·¡ç¶ 
            ],
            'threshold': {
                'line': {'color': "black", 'width': 3},
                'thickness': 0.75,
                'value': score
            }
        }
    ))
    fig.update_layout(
        height=250, 
        margin=dict(l=20, r=20, t=40, b=20),
        paper_bgcolor='rgba(0,0,0,0)',
        font={'family': "Arial"}
    )
    return fig

def get_verdict(score):
    if score > 80:
        return "âœ… é«˜æ©Ÿç‡ç‚ºäººé¡æ’°å¯«"
    elif score > 50:
        return "âš ï¸ å¯èƒ½ç‚ºæ··åˆå…§å®¹ / æ¨¡ç¨œå…©å¯"
    else:
        return "ğŸ¤– é«˜æ©Ÿç‡ç”± AI ç”Ÿæˆ"

# ==========================================
# 4. ä¸»ç¨‹å¼é‚è¼¯
# ==========================================
def main():
    # --- å´é‚Šæ¬„ (Sidebar) ---
    with st.sidebar:
        st.header("ğŸ›¡ï¸ AI Sentinel")
        st.caption("ç‰ˆæœ¬ v3.5 | é›™æ¨¡å‹äº¤å‰é©—è­‰")
        st.markdown("---")
        st.info(
            """
            **ğŸ“Š åˆ¤è®€æŒ‡å—ï¼š**
            æœ¬å·¥å…·ä½¿ç”¨ **é›™æ¨¡å‹åˆ†æ** ä¾†æå‡æº–ç¢ºåº¦ã€‚
            ç¶œåˆè©•åˆ†æ˜¯å…©å€‹æ¨¡å‹çµæœçš„åŠ æ¬Šå¹³å‡å€¼ã€‚
            """
        )
        st.markdown("### ä½¿ç”¨æ¨¡å‹")
        st.markdown(
            """
            æ­¤å·¥å…·æ•´åˆäº†å…©æ¬¾ä¸åŒæ¶æ§‹çš„é è¨“ç·´æ¨¡å‹ï¼š
            - **ModernBERT**: æ–°ä¸€ä»£é«˜æ•ˆèƒ½æ¶æ§‹ã€‚
            - **RoBERTa**: ç¶“å…¸ä¸”ç©©å®šçš„ AI åµæ¸¬æ¨¡å‹ã€‚
            
            **ğŸ’¡ æ³¨æ„ï¼š**
            åµæ¸¬å…ˆé€² AI (å¦‚ GPT-4o) ç”Ÿæˆçš„æ–‡æœ¬æ¥µå…·æŒ‘æˆ°æ€§ï¼Œ
            çµæœåƒ…ä¾›åƒè€ƒï¼Œä¸æ‡‰ä½œç‚ºçµ•å°ä¾æ“šã€‚
            """
        )
        st.markdown("---")
        st.caption("Designed for HW5")

    # --- è¼‰å…¥æ¨¡å‹ ---
    with st.spinner("æ­£åœ¨è¼‰å…¥ AI åµæ¸¬æ¨¡å‹ï¼Œè«‹ç¨å€™..."):
        active_pipelines = load_detectors()

    # --- ä¸»æ¨™é¡Œ ---
    st.title("ğŸ•µï¸â€â™‚ï¸ å°ˆæ¥­ç´š AI å…§å®¹æª¢æ¸¬å„€")
    st.markdown("#### é€éé›™æ¨¡å‹äº¤å‰é©—è­‰ï¼Œæå‡åˆ†æçš„å¯ä¿¡åº¦")
    st.markdown("---")
    
    if 'text_content' not in st.session_state:
        st.session_state.text_content = ""

    # ç¯„ä¾‹æ–‡å­—åº«
    sample_texts = {
        "AI": [
            "Leveraging synergistic paradigms, our holistic framework proactively optimizes scalable, next-generation architectures to empower enterprise-level stakeholders and ensure robust, end-to-end platform integration.",
            "The subject vehicle, a 2022 sedan, was observed proceeding northbound at a velocity of 58 kilometers per hour. Weather conditions were optimal. No anomalous events were recorded during the observation period.",
            "A computer is an electronic device that manipulates information, or data. It has the ability to store, retrieve, and process data. You can use a computer to type documents, send email, play games, and browse the Web.",
            "The benefits of this system are numerous. The first benefit is efficiency. The second benefit is scalability. The third benefit is security. The fourth benefit is cost-effectiveness. The fifth benefit is user-friendliness.",
            "The ontological nature of consciousness represents a persistent enigma within neuro-scientific inquiry, where emergent properties of subjective experience defy simple reductionist explanations."
        ],
        "Human": [
            "Are you kidding me with this wifi right now?! It's been cutting out all morning and I have a huge deadline. I swear, I've tried restarting the router like, a million times. I'm about to lose my mind.",
            "My grandma's kitchen always smelled like cinnamon and fresh bread. I remember being a little kid, sitting on a stool that was way too tall for me, just watching her knead dough. I miss those simple afternoons.",
            "OMG I GOT THE TICKETS!!! I can't believe it, they sold out in like 30 seconds but I was fast enough. My hands are still shaking. This is going to be the best concert EVER. I'm already planning my outfit, haha!",
            "Idk, I just feel like pineapple on pizza isn't as bad as people make it out to be. It's like, a little bit of sweet to balance out the salty. Not my go-to order, but I won't be mad if it's there, you know?",
            "My cat has this weird habit where he only drinks water if it's from my glass. I'll have a full, fresh bowl for him, but he'll just stare at it and then try to stick his head in my cup. What a weirdo. Love him though.",
            "Okay, so for the potluck, I'll bring the mac and cheese. Can you grab a dessert? Maybe that lemon tart from the bakery on 5th street? Let me know what you think. We still need someone to bring drinks.",
            "wait wait I typed the wrong thingâ€”hold onâ€”ok NOW it makes sense. I think.",
            "ngl Iâ€™m so tired I just stared at my screen for likeâ€¦ a full minute. doing nothing. just staring.",
            "bro why did I randomly remember that one dumb thing I said in 7th grade?? who asked for this pain.",
            "okay but why did my brain suddenly remember something embarrassing from 10 years ago. for WHAT.",
            "why is my brain bringing up that cringe moment from forever ago right NOW of all times. like pls stop.",
            "not my brain dropping a random embarrassment bomb from 2014 while Iâ€™m literally doing nothing. WHY.",
            "why did my mind just throw a random â€œremember when you embarrassed yourself in front of everyoneâ€ flashback at me for NO reason."
        ],
    }

    # --- é›™æ¬„ä½ˆå±€ ---
    col1, col2 = st.columns([1.2, 1], gap="large")

    # --- Sample Logic ---
    all_samples = sample_texts["AI"] + sample_texts["Human"]
    if 'available_indices' not in st.session_state:
        st.session_state.available_indices = list(range(len(all_samples)))

    # === å·¦å´ï¼šè¼¸å…¥å€ ===
    with col1:
        st.subheader("ğŸ“ è¼¸å…¥å¾…æ¸¬æ–‡æœ¬")
        
        st.write("å¿«é€Ÿæ¸¬è©¦ç¯„ä¾‹ï¼š")
        btn_cols = st.columns([1, 1])
        if btn_cols[0].button("éš¨æ©Ÿç¯„ä¾‹ (Random Sample)", key="random_sample"):
            if not st.session_state.available_indices:
                st.session_state.available_indices = list(range(len(all_samples)))
                st.toast("æ‰€æœ‰ç¯„ä¾‹å·²é¡¯ç¤ºå®Œç•¢ï¼Œåˆ—è¡¨å·²é‡ç½®ã€‚")

            random_index = random.choice(st.session_state.available_indices)
            st.session_state.text_content = all_samples[random_index]
            st.session_state.available_indices.remove(random_index)
            st.rerun()

        if btn_cols[1].button("ğŸ—‘ï¸ æ¸…ç©º", key="clear"):
            st.session_state.text_content = ""
            st.rerun()

        input_text = st.text_area(
            "è«‹åœ¨æ­¤è²¼ä¸Šæ–‡ç« å…§å®¹ (å»ºè­°è‹±æ–‡):",
            value=st.session_state.text_content,
            height=350,
            placeholder="è«‹è¼¸å…¥è‡³å°‘ 3 å€‹å–®å­—ä»¥ç²å¾—æœ€ä½³æº–ç¢ºåº¦..."
        )
        
        word_count = len(input_text.split())
        st.caption(f"ç›®å‰å­—æ•¸: {word_count} words")

        analyze_btn = st.button("ğŸ” é–‹å§‹äº¤å‰åˆ†æ", type="primary", use_container_width=True, disabled=(not active_pipelines))

    # === å³å´ï¼šçµæœå€ ===
    with col2:
        st.subheader("ğŸ“Š ç¶œåˆåˆ†æå ±å‘Š")
        
        if not active_pipelines:
            st.error("âŒ ç„¡æ³•è¼‰å…¥ä»»ä½• AI æ¨¡å‹ï¼Œæ‡‰ç”¨ç¨‹å¼ç„¡æ³•é‹ä½œã€‚è«‹æª¢æŸ¥æ‚¨çš„ç¶²è·¯é€£ç·šå¾Œï¼Œé‡æ–°æ•´ç†é é¢ã€‚")
        elif analyze_btn:
            if not input_text.strip():
                st.warning("âš ï¸ è«‹å…ˆè¼¸å…¥æ–‡å­—å…§å®¹ï¼")
            elif word_count < 3: 
                st.warning("âš ï¸ æ–‡å­—å…§å®¹éçŸ­ï¼Œè«‹è¼¸å…¥è‡³å°‘ 3 å€‹å–®å­—ã€‚")
            else:
                with st.spinner(f"æ­£åœ¨ä½¿ç”¨ {len(active_pipelines)} å€‹æ¨¡å‹é€²è¡Œäº¤å‰é©—è­‰..."):
                    safe_text = clean_text(input_text)
                    start_time = time.time()
                    
                    scores = []
                    results_detail = []

                    # è¿­ä»£æ‰€æœ‰æˆåŠŸè¼‰å…¥çš„æ¨¡å‹
                    for item in active_pipelines:
                        pipe = item['pipe']
                        name = item['name']
                        
                        try:
                            # !!! é—œéµä¿®æ­£: åŠ å…¥ truncation=True èˆ‡ max_length !!!
                            # é€™æ˜¯é˜²æ­¢é•·æ–‡ç« å°è‡´ç¨‹å¼å´©æ½°çš„é—œéµ
                            # åªå–å‰ 512 tokens é€²è¡Œé æ¸¬
                            prediction = pipe(safe_text, truncation=True, max_length=512)[0]
                            
                            # è§£æåˆ†æ•¸ (çµ±ä¸€è½‰æ›ç‚ºã€Œäººé¡æ©Ÿç‡ã€)
                            label = prediction['label']
                            score = prediction['score']
                            
                            human_prob = 0.0
                            # ä¸åŒæ¨¡å‹çš„æ¨™ç±¤å®šç¾©å¯èƒ½ä¸åŒï¼Œé€™è£¡åšé€šç”¨è™•ç†
                            
                            if name == "ModernBERT Detector":
                                # å‡è¨­: LABEL_0=Human, LABEL_1=AI
                                if label == 'LABEL_0': 
                                    human_prob = score
                                else:
                                    human_prob = 1 - score
                                    
                            elif name == "RoBERTa Detector":
                                # Hello-SimpleAI/chatgpt-detector-roberta
                                # Human, ChatGPT
                                if label in ['Human', 'Real', 'LABEL_1']: # 'LABEL_1' for some RoBERTa variants
                                    human_prob = score
                                else: # ChatGPT, Fake, LABEL_0
                                    human_prob = 1 - score
                            
                            scores.append(human_prob)
                            results_detail.append({
                                "name": name,
                                "prob": human_prob,
                                "raw": prediction
                            })
                            
                        except Exception as e:
                            st.error(f"æ¨¡å‹ {name} åˆ†ææ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")

                    end_time = time.time()

                    if scores:
                        # è¨ˆç®—å¹³å‡åˆ†æ•¸
                        avg_human_prob = sum(scores) / len(scores)
                        avg_human_score_percent = avg_human_prob * 100

                        # 1. é¡¯ç¤ºç¶œåˆå„€è¡¨æ¿
                        st.plotly_chart(create_gauge_chart(avg_human_score_percent, title="ç¶œåˆè©•åˆ† (å¹³å‡)"), use_container_width=True)
                        st.markdown(f"<h3 style='text-align: center; color: #FFF;'>{get_verdict(avg_human_score_percent)}</h3>", unsafe_allow_html=True)
                        
                        st.markdown("---")
                        
                        # 2. é¡¯ç¤ºå„æ¨¡å‹ç´°ç¯€
                        st.write("##### ğŸ”¬ é›™æ¨¡å‹äº¤å‰æ¯”å°çµæœï¼š")
                        
                        for i, res in enumerate(results_detail):
                            st.markdown(f"#### {i+1}. {res['name']}")
                            
                            # Explain the logic
                            raw_label = res['raw']['label']
                            raw_score = res['raw']['score']
                            
                            st.write("**æ¨¡å‹åˆ¤è®€é‚è¼¯:**")
                            explanation = ""
                            if "ModernBERT" in res['name']:
                                if raw_label == 'LABEL_0':
                                    explanation = f"æ¨¡å‹å›å‚³æ¨™ç±¤ '{raw_label}' ä»£è¡¨ **äººé¡**ï¼Œå…¶ä¿¡å¿ƒåˆ†æ•¸ç‚º **{raw_score:.2%}**ã€‚å› æ­¤ï¼Œæˆ‘å€‘å°‡æ­¤åˆ†æ•¸ç›´æ¥è¦–ç‚ºäººé¡æ©Ÿç‡ã€‚"
                                else: # LABEL_1
                                    explanation = f"æ¨¡å‹å›å‚³æ¨™ç±¤ '{raw_label}' ä»£è¡¨ **AI**ï¼Œå…¶ä¿¡å¿ƒåˆ†æ•¸ç‚º **{raw_score:.2%}**ã€‚å› æ­¤ï¼Œäººé¡æ©Ÿç‡ç‚º 100% - {raw_score:.2%} = **{1-raw_score:.2%}**ã€‚"
                            elif "RoBERTa" in res['name']:
                                if raw_label in ['Human', 'Real', 'LABEL_1']:
                                    explanation = f"æ¨¡å‹å›å‚³æ¨™ç±¤ '{raw_label}' ä»£è¡¨ **äººé¡**ï¼Œå…¶ä¿¡å¿ƒåˆ†æ•¸ç‚º **{raw_score:.2%}**ã€‚å› æ­¤ï¼Œæˆ‘å€‘å°‡æ­¤åˆ†æ•¸ç›´æ¥è¦–ç‚ºäººé¡æ©Ÿç‡ã€‚"
                                else: # ChatGPT, Fake, LABEL_0
                                    explanation = f"æ¨¡å‹å›å‚³æ¨™ç±¤ '{raw_label}' ä»£è¡¨ **AI**ï¼Œå…¶ä¿¡å¿ƒåˆ†æ•¸ç‚º **{raw_score:.2%}**ã€‚å› æ­¤ï¼Œäººé¡æ©Ÿç‡ç‚º 100% - {raw_score:.2%} = **{1-raw_score:.2%}**ã€‚"
                            
                            st.info(explanation, icon="ğŸ§ ")

                            st.write(f"**æœ€çµ‚æ¨æ–·çš„äººé¡æ©Ÿç‡:**")
                            st.progress(res['prob'])
                            st.caption(f"è¨ˆç®—å‡ºçš„æ©Ÿç‡ç‚º **{res['prob']:.2%}**ï¼Œçµè«–ç‚º: **{get_verdict(res['prob']*100)}**")
                            
                            if i < len(results_detail) - 1:
                                st.markdown("---")

                        # 3. æŠ€è¡“ç´°ç¯€
                        st.markdown("---")
                        with st.expander("æŸ¥çœ‹ç¶œåˆæŠ€è¡“æ•¸æ“š (JSON)"):
                            st.json({
                                "ç¶œåˆäººé¡æ©Ÿç‡": f"{avg_human_prob:.4f}",
                                "æ¨è«–æ™‚é–“": f"{end_time - start_time:.3f} ç§’",
                                "å„æ¨¡å‹è©³ç´°è¼¸å‡º": results_detail
                            })
                    else:
                        st.error("åˆ†æéç¨‹ç™¼ç”ŸéŒ¯èª¤ï¼Œç„¡æ³•ç”¢ç”Ÿåˆ†æ•¸ã€‚")

        else:
            st.info("ğŸ‘ˆ è«‹åœ¨å·¦å´è¼¸å…¥æ–‡ç« ï¼Œä¸¦é»æ“ŠæŒ‰éˆ•é–‹å§‹åˆ†æã€‚")
            st.markdown(
                """
                <div style="background-color:#262730; padding:20px; border-radius:10px; border: 1px solid #444;">
                <h4 style="margin-top:0; color: white;">ğŸ’¡ ç‚ºä½•ä½¿ç”¨é›™æ¨¡å‹ï¼Ÿ</h4>
                <p style="color: #ccc;">å–®ä¸€æ¨¡å‹å¯èƒ½å­˜åœ¨åè¦‹æˆ–ç›²é»ã€‚é€éäº¤å‰æ¯”å°å…©å€‹ä¾†è‡ªä¸åŒè¨“ç·´ä¾†æºçš„æ¨¡å‹ (Ensemble Learning)ï¼Œæˆ‘å€‘å¯ä»¥ç²å¾—æ›´å¹³è¡¡ã€æ›´å¯é çš„åˆ¤æ–·ï¼Œæœ‰æ•ˆé™ä½èª¤åˆ¤ç‡ã€‚</p>
                </div>
                """, unsafe_allow_html=True
            )

if __name__ == "__main__":
    main()