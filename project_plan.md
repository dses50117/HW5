# Project Plan: Building the AI Detector with CRISP-DM

This document explains how the AI Content Detector application was built, using the **Cross-Industry Standard Process for Data Mining (CRISP-DM)** as a guide.

The CRISP-DM model provides a structured approach for data science projects. It consists of 6 phases. Below, we describe what was done in each phase for this specific project.

---
# Project Plan: Building the AI Detector with CRISP-DM

This document explains how the AI Content Detector application was built, using the **Cross-Industry Standard Process for Data Mining (CRISP-DM)** as a guide.

The CRISP-DM model provides a structured approach for data science projects. It consists of 6 phases. Below, we describe what was done in each phase for this specific project.

---

### Phase 1: Business Understanding

This is the starting point of any project. The goal is to understand what the business needs.

*   **Objective:** The user wanted to build a web application that could detect AI-generated text. The look and feel should be similar to a professional AI detector website.
*   **Project Goal:** The immediate goal was to create a working **prototype** of this application using Streamlit. This prototype should have a user-friendly interface and demonstrate the intended functionality, even if the underlying AI detection is not real yet.
*   **Success Criteria:** The project is successful if we have a running Streamlit app that allows a user to input text and see a simulated analysis result, and the project is successfully set up on GitHub.

---

### Phase 2: Data Understanding

This phase involves getting familiar with the data that will be used to build the model.

*   **What We Did (Prototype):**
    *   For this prototype, we did **not** use a real dataset.
    *   To demonstrate the "Use Sample" feature, we created a small, hardcoded list of sample texts inside the `app.py` file. This is placeholder data.
    ```python
    sample_texts = [
        "The quick brown fox jumps over the lazy dog...",
        # ... more sample sentences
    ]
    ```

*   **What a Real Project Would Do:**
    *   **Data Collection:** Collect thousands of text examples. Half would be written by humans (from books, blogs, news) and the other half would be generated by various AI models (like GPT-3, Llama, etc.).
    *   **Data Exploration:** Analyze this data to find patterns. For example, we would compare the average sentence length, the variety of words used, and the grammatical structure of human text vs. AI text.

---

### Phase 3: Data Preparation

This phase involves cleaning and structuring the data before it can be used for modeling.

*   **What We Did (Prototype):**
    *   Since we did not have a real dataset, this phase was **not applicable**.

*   **What a Real Project Would Do:**
    *   **Cleaning:** Remove any irrelevant information (like HTML tags or ads) from the collected texts.
    *   **Formatting:** Ensure all text is in a consistent format.
    *   **Splitting:** Divide the data into a training set (to teach the model) and a testing set (to see how well the model performs on new data).

---

### Phase 4: Modeling

This is where the actual AI model is created.

*   **What We Did (Prototype):**
    *   We **simulated** the behavior of an AI model.
    *   We used Python's `random` library to generate a fake "human score". This allowed us to build the app's user interface without needing a real, trained model.
    ```python
    # This line pretends to be a real AI model
    human_score = random.randint(50, 100)
    ```

*   **What a Real Project Would Do:**
    *   **Model Selection:** Choose a suitable machine learning algorithm. For text, models like `BERT` or `RoBERTa` from Hugging Face are powerful choices.
    *   **Training:** "Train" the chosen model on the prepared training data. The model learns the patterns that distinguish human writing from AI writing.

---

### Phase 5: Evaluation

This phase is about checking how well the model performs.

*   **What We Did (Prototype):**
    *   Our evaluation was focused on the **user interface**. We tested the app to make sure the buttons worked, the text area updated correctly, and the results were displayed clearly.
    *   We fixed bugs related to the app's functionality, not the model's accuracy.

*   **What a Real Project Would Do:**
    *   **Performance Testing:** Use the testing set (which the model has never seen) to measure the model's accuracy. We would ask: "What percentage of the time does the model correctly identify a text as AI or human?"
    *   **Metrics:** Use metrics like Precision, Recall, and F1-score to get a detailed understanding of the model's strengths and weaknesses.

---

### Phase 6: Deployment

This final phase is about making the project available to users. This was the main focus of our work.

*   **What We Did (Prototype):**
    1.  **Wrote the Application:** We wrote the full application code in `app.py` using Streamlit.
    2.  **Built the UI:** We created the title, text area, and buttons.
    3.  **Handled User Interaction:** We used `st.session_state` to make the app interactive and responsive.
    4.  **Set up for GitHub:** We created a `.gitignore`, a `README.md`, and organized the code to be shared on GitHub.
    5.  **"Deployed" Locally:** We made the app runnable on the user's machine with the command:
        ```bash
        streamlit run app.py
        ```

*   **What a Real Project Would Do:**
    *   **Integration:** The trained and evaluated AI model from Phase 4 and 5 would be integrated into the Streamlit app, replacing the random number generator.
    *   **Hosting:** The application would be hosted on a cloud platform (like Streamlit Community Cloud or AWS) so that anyone could access it with a web link.
